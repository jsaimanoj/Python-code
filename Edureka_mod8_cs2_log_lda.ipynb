{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.chdir('C:\\\\Users\\\\Manoj\\\\Desktop\\\\Edureka_Python')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.data\n",
    "y = data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manoj\\Anaconda3\\lib\\site-packages\\sklearn\\discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "lda = LinearDiscriminantAnalysis(n_components=8)\n",
    "X_lda = lda.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_var_ratios = lda.explained_variance_ratio_\n",
    "lda_var_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.28912041, 0.18262788, 0.16962345, 0.1167055 , 0.08301253,\n",
       "       0.06565685, 0.04310127, 0.0293257 ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_var_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function\n",
    "def select_n_components(var_ratio, goal_var: float) -> int:\n",
    "    # Set initial variance explained so far\n",
    "    total_variance = 0.0\n",
    "    \n",
    "    # Set initial number of features\n",
    "    n_components = 0\n",
    "    \n",
    "    # For the explained variance of each feature:\n",
    "    for explained_variance in var_ratio:\n",
    "        \n",
    "        # Add the explained variance to the total\n",
    "        total_variance += explained_variance\n",
    "        \n",
    "        # Add one to the number of components\n",
    "        n_components += 1\n",
    "        \n",
    "        # If we reach our goal level of explained variance\n",
    "        if total_variance >= goal_var:\n",
    "            # End the loop\n",
    "            break\n",
    "            \n",
    "    # Return the number of components\n",
    "    return n_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "select_n_components(lda_var_ratios, 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train , y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manoj\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Manoj\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logmodel = LogisticRegression()\n",
    "logmodel.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logmodel.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[41,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0, 33,  0,  0,  0,  0,  0,  0,  1,  0],\n",
       "       [ 0,  0, 41,  1,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0, 36,  0,  0,  0,  0,  1,  0],\n",
       "       [ 0,  0,  0,  0, 30,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0, 33,  0,  1,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0, 32,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0, 37,  0,  0],\n",
       "       [ 0,  2,  0,  0,  0,  0,  0,  0, 27,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  1, 42]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for classifier SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99        88\n",
      "           1       0.99      0.97      0.98        91\n",
      "           2       0.99      0.99      0.99        86\n",
      "           3       0.98      0.87      0.92        91\n",
      "           4       0.99      0.96      0.97        92\n",
      "           5       0.95      0.97      0.96        91\n",
      "           6       0.99      0.99      0.99        91\n",
      "           7       0.96      0.99      0.97        89\n",
      "           8       0.94      1.00      0.97        88\n",
      "           9       0.93      0.98      0.95        92\n",
      "\n",
      "   micro avg       0.97      0.97      0.97       899\n",
      "   macro avg       0.97      0.97      0.97       899\n",
      "weighted avg       0.97      0.97      0.97       899\n",
      "\n",
      "\n",
      "Confusion matrix:\n",
      "[[87  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 88  1  0  0  0  0  0  1  1]\n",
      " [ 0  0 85  1  0  0  0  0  0  0]\n",
      " [ 0  0  0 79  0  3  0  4  5  0]\n",
      " [ 0  0  0  0 88  0  0  0  0  4]\n",
      " [ 0  0  0  0  0 88  1  0  0  2]\n",
      " [ 0  1  0  0  0  0 90  0  0  0]\n",
      " [ 0  0  0  0  0  1  0 88  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 88  0]\n",
      " [ 0  0  0  1  0  1  0  0  0 90]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import datasets, svm, metrics\n",
    "\n",
    "# The digits dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# The data that we are interested in is made of 8x8 images of digits, let's\n",
    "# have a look at the first 4 images, stored in the `images` attribute of the\n",
    "# dataset.  If we were working from image files, we could load them using\n",
    "# matplotlib.pyplot.imread.  Note that each image must have the same size. For these\n",
    "# images, we know which digit they represent: it is given in the 'target' of\n",
    "# the dataset.\n",
    "images_and_labels = list(zip(digits.images, digits.target))\n",
    "for index, (image, label) in enumerate(images_and_labels[:4]):\n",
    "    plt.subplot(2, 4, index + 1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Training: %i' % label)\n",
    "\n",
    "# To apply a classifier on this data, we need to flatten the image, to\n",
    "# turn the data in a (samples, feature) matrix:\n",
    "n_samples = len(digits.images)\n",
    "data = digits.images.reshape((n_samples, -1))\n",
    "\n",
    "# Create a classifier: a support vector classifier\n",
    "classifier = svm.SVC(gamma=0.001)\n",
    "\n",
    "# We learn the digits on the first half of the digits\n",
    "classifier.fit(data[:n_samples // 2], digits.target[:n_samples // 2])\n",
    "\n",
    "# Now predict the value of the digit on the second half:\n",
    "expected = digits.target[n_samples // 2:]\n",
    "predicted = classifier.predict(data[n_samples // 2:])\n",
    "\n",
    "print(\"Classification report for classifier %s:\\n%s\\n\"\n",
    "      % (classifier, metrics.classification_report(expected, predicted)))\n",
    "print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(expected, predicted))\n",
    "\n",
    "images_and_predictions = list(zip(digits.images[n_samples // 2:], predicted))\n",
    "for index, (image, prediction) in enumerate(images_and_predictions[:4]):\n",
    "    plt.subplot(2, 4, index + 5)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(image, cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "    plt.title('Prediction: %i' % prediction)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
